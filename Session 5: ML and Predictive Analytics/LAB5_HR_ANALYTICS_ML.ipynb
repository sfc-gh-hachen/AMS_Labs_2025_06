{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "atklndfydjsshuedyo5q",
   "authorId": "5126471379346",
   "authorName": "HCHEN",
   "authorEmail": "harley.chen@snowflake.com",
   "sessionId": "56248de2-d18e-4125-b2ac-b24b888d0b30",
   "lastEditTime": 1749917437227
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "import_packages"
   },
   "source": "# Import required libraries for Snowflake ML\nimport pandas as pd\nimport numpy as np\nimport streamlit as st\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom snowflake.snowpark import Window\nimport snowflake.snowpark.functions as F\nfrom snowflake.snowpark.types import LongType\nfrom snowflake.ml.modeling.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom snowflake.ml.modeling.xgboost import XGBClassifier\nfrom snowflake.ml.modeling.model_selection import GridSearchCV\nfrom snowflake.ml.modeling.metrics import accuracy_score, roc_auc_score\nfrom snowflake.ml.registry import Registry\n\nwarnings.filterwarnings('ignore')\n\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nprint(\"Libraries imported successfully\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b4f9f828-1dc4-489d-aa57-64fe8a640590",
   "metadata": {
    "language": "python",
    "name": "env_settings"
   },
   "outputs": [],
   "source": "import sys\nsnowflake_environment = session.sql('select current_user(), current_version()').collect()\nfrom snowflake.snowpark.version import VERSION\nfrom snowflake.ml import version\n\n# Current Environment Details\nprint('User                        : {}'.format(snowflake_environment[0][0]))\nprint('Role                        : {}'.format(session.get_current_role()))\nprint('Database                    : {}'.format(session.get_current_database()))\nprint('Schema                      : {}'.format(session.get_current_schema()))\nprint('Warehouse                   : {}'.format(session.get_current_warehouse()))\nprint('Snowflake version           : {}'.format(snowflake_environment[0][1]))\nprint('Snowpark for Python version : {}.{}.{}'.format(VERSION[0],VERSION[1],VERSION[2]))\nprint('Snowflake ML version        : {}.{}.{}'.format(version.VERSION[0],version.VERSION[2],version.VERSION[4]))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae356b71-d916-4433-80d3-5dc0612438ca",
   "metadata": {
    "language": "sql",
    "name": "raw_data"
   },
   "outputs": [],
   "source": "select * from HR_EMPLOYEE_ATTRITION;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2a75349e-87c8-44e2-a331-9acf3dde67dc",
   "metadata": {
    "language": "python",
    "name": "raw_data_dataframe"
   },
   "outputs": [],
   "source": "# Load raw data from HR_EMPLOYEE_ATTRITION table\nraw_data_df = session.table(\"HR_EMPLOYEE_ATTRITION\")\n\n# We can also make references to the cells in the notebook\n# raw_data_df = raw_data.to_df()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "dataset_schema"
   },
   "source": "# Basic dataset overview using Snowpark DataFrame methods\nprint(\"üìã DATASET OVERVIEW\")\nprint(\"=\" * 50)\n\n# Get row count and column info\nrow_count = raw_data_df.count()\ncolumn_count = len(raw_data_df.columns)\nprint(f\"Shape: {row_count} rows √ó {column_count} columns\")\n\n# Show column names and types\nprint(f\"\\nüìä Columns and Types:\")\nfor field in raw_data_df.schema.fields:\n    print(f\"   {field.name}: {field.datatype}\")\n\nprint(f\"\\nüìà First 5 rows:\")\nst.dataframe(raw_data_df.limit(5))\n\n# Check for missing values and data quality using Snowpark DataFrame\nprint(\"üîç DATA QUALITY CHECKS\")\nprint(\"=\" * 50)\n\n# Check for duplicates by comparing total rows vs distinct rows\ntotal_rows = raw_data_df.count()\ndistinct_rows = raw_data_df.distinct().count()\nduplicates = total_rows - distinct_rows\nprint(f\"\\nüîÑ Duplicate rows: {duplicates}\")\n\n# Basic statistical summary for numerical columns\nprint(f\"\\nüìä Statistical Summary (key numerical columns):\")\nnumerical_stats = raw_data_df.select([\n    F.avg(\"AGE\").alias(\"avg_age\"),\n    F.min(\"AGE\").alias(\"min_age\"), \n    F.max(\"AGE\").alias(\"max_age\"),\n    F.avg(\"MONTHLY_INCOME\").alias(\"avg_income\"),\n    F.min(\"MONTHLY_INCOME\").alias(\"min_income\"),\n    F.max(\"MONTHLY_INCOME\").alias(\"max_income\"),\n    F.avg(\"YEARS_AT_COMPANY\").alias(\"avg_tenure\"),\n    F.max(\"YEARS_AT_COMPANY\").alias(\"max_tenure\")\n])\nst.dataframe(numerical_stats)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "62c867a4-9af1-4419-abee-46e0020fe4ad",
   "metadata": {
    "language": "python",
    "name": "data_discovery"
   },
   "outputs": [],
   "source": "# Basic Data Discovery - Check missing values and Drop unnecessary columns\nst.header(\"üîç Basic Data Discovery\")\nst.markdown(\"---\")\n\nst.write(\"Data is cleaned and have no missing value.\")\nst.write(\"Since the number of columns are overwhelming, it is plausible to retain the most crucial valuesets in relation to our analytical purposes.\")\n\n# Check for problematic columns exactly as in Medium post\nproblematic_cols = ['EMPLOYEE_COUNT', 'EMPLOYEE_NUMBER', 'STANDARD_HOURS', 'OVER18', 'PERFORMANCE_RATING']\ncols_to_drop = []\n\nst.subheader(\"Columns to analyze:\")\nfor col_name in problematic_cols:\n    if col_name in raw_data_df.columns:\n        unique_vals = raw_data_df.select(col_name).distinct().collect()\n        unique_count = len(unique_vals)\n        vals = [row[col_name] for row in unique_vals]\n        \n        if col_name == 'EMPLOYEE_COUNT':\n            st.write(f\"- **{col_name}**: consists of 1 value only ({vals}) - can be omitted\")\n            cols_to_drop.append(col_name)\n        elif col_name == 'OVER18':\n            st.write(f\"- **{col_name}**: consists of 1 value only ({vals}) - can be omitted\")  \n            cols_to_drop.append(col_name)\n        elif col_name == 'STANDARD_HOURS':\n            st.write(f\"- **{col_name}**: consists of 1 value only ({vals}) - can be omitted\")\n            cols_to_drop.append(col_name)\n        elif col_name == 'EMPLOYEE_NUMBER':\n            st.write(f\"- **{col_name}**: is employee ID, which is unique for each entry - keeping for reference\")\n        elif col_name == 'PERFORMANCE_RATING':\n            st.write(f\"- **{col_name}**: consists of merely {unique_count} values ({vals}) - limited analytical value\")\n            cols_to_drop.append(col_name)\n\n# Drop columns\nif cols_to_drop:\n    st.subheader(\"Drop some columns\")\n    st.write(f\"Dropping: {cols_to_drop}\")\n    cleaned_df = raw_data_df.drop(*cols_to_drop)\n    st.success(f\"Dropped {len(cols_to_drop)} columns\")\nelse:\n    cleaned_df = raw_data_df\n\n# Removing Outliers\nst.subheader(\"Removing Outliers\")\nst.write(\"There are outliers in some columns, but either the number of outliers is small (<5%) or the outliers values are in realistic, reasonable range. Except for monthly_income column.\")\n\n# Calculate quartiles for monthly income\nincome_stats = cleaned_df.select([\n    F.expr(\"percentile_cont(0.25) within group (order by MONTHLY_INCOME)\").alias(\"Q1\"),\n    F.expr(\"percentile_cont(0.75) within group (order by MONTHLY_INCOME)\").alias(\"Q3\"),\n    F.count(\"*\").alias(\"total_rows\")\n]).collect()[0]\n\n# Convert to float to avoid Decimal multiplication issues\nQ1 = float(income_stats['Q1'])\nQ3 = float(income_stats['Q3']) \nIQR = Q3 - Q1\nlower_bound_calc = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\n# Income cannot be negative - use reasonable minimum instead\nimport builtins\nlower_bound = builtins.max(0, lower_bound_calc)  # Ensure positive lower bound\n\n# Show outlier analysis before removal\nst.subheader(\"üìä Outlier Analysis - Monthly Income\")\n\n# Display outlier statistics\ncol1, col2, col3 = st.columns(3)\nwith col1:\n    st.metric(\"Q1 (25th percentile)\", f\"${Q1:,.0f}\")\nwith col2:\n    st.metric(\"Q3 (75th percentile)\", f\"${Q3:,.0f}\")\nwith col3:\n    st.metric(\"IQR\", f\"${IQR:,.0f}\")\n\ncol1, col2 = st.columns(2)\nwith col1:\n    st.metric(\"Lower Bound\", f\"${lower_bound:,.0f}\")\nwith col2:\n    st.metric(\"Upper Bound\", f\"${upper_bound:,.0f}\")\n\n# Get sample data for visualization (convert small sample to pandas for plotting)\nincome_sample = cleaned_df.select(\"MONTHLY_INCOME\").limit(1000).to_pandas()\n\n# Create histogram showing outliers\nfig, ax = plt.subplots(figsize=(10, 6))\nax.hist(income_sample['MONTHLY_INCOME'], bins=50, alpha=0.7, color='lightblue', edgecolor='black')\nax.axvline(lower_bound, color='red', linestyle='--', linewidth=2, label=f'Lower Bound: ${lower_bound:,.0f}')\nax.axvline(upper_bound, color='red', linestyle='--', linewidth=2, label=f'Upper Bound: ${upper_bound:,.0f}')\nax.axvline(Q1, color='green', linestyle='-', alpha=0.7, label=f'Q1: ${Q1:,.0f}')\nax.axvline(Q3, color='green', linestyle='-', alpha=0.7, label=f'Q3: ${Q3:,.0f}')\nax.set_xlabel('Monthly Income ($)')\nax.set_ylabel('Frequency')\nax.set_title('Monthly Income Distribution with Outlier Boundaries')\nax.legend()\nax.grid(axis='y', alpha=0.3)\nst.pyplot(fig)\nplt.close()\n\n# Count and identify outliers\noutliers_df = cleaned_df.filter(\n    (F.col(\"MONTHLY_INCOME\") < lower_bound) | (F.col(\"MONTHLY_INCOME\") > upper_bound)\n)\noutlier_count = outliers_df.count()\ntotal_count = cleaned_df.count()\noutlier_percentage = (outlier_count / total_count) * 100\n\nst.subheader(\"üéØ Rationale for Outlier Removal\")\n\ncol1, col2 = st.columns(2)\nwith col1:\n    st.metric(\"Outliers Found\", f\"{outlier_count} records\")\nwith col2:\n    st.metric(\"Percentage of Data\", f\"{outlier_percentage:.1f}%\")\n\nif lower_bound_calc < 0:\n    st.warning(f\"‚ö†Ô∏è Standard IQR lower bound would be ${lower_bound_calc:,.0f} (negative), adjusted to $0\")\n\nst.markdown(f\"\"\"\n**Why we're removing these outliers:**\n\n1. **Statistical Reason**: Using modified IQR method - values above ${upper_bound:,.0f} are considered outliers.\n   - Original lower bound: ${lower_bound_calc:,.0f} ‚Üí Adjusted to ${lower_bound:,.0f} (income cannot be negative)\n\n2. **Business Logic**: \n   - **Lower bound** (${lower_bound:,.0f}): Set to zero since income cannot be negative\n   - **Upper outliers** (> ${upper_bound:,.0f}): Likely executive compensation that could skew our analysis of typical employee attrition patterns\n\n3. **Model Performance**: Extreme high values can:\n   - Skew statistical measures (mean, standard deviation)\n   - Reduce the effectiveness of machine learning algorithms\n   - Make it harder to identify patterns for the majority of employees\n\n4. **Data Quality**: Only {outlier_percentage:.1f}% of the data - small enough that removal won't significantly impact our analysis but will improve model quality.\n\n**Decision**: Remove {outlier_count} outlier records to focus on typical employee compensation patterns.\n\"\"\")\n\n# Remove outliers\nfinal_df = cleaned_df.filter(\n    (F.col(\"MONTHLY_INCOME\") >= lower_bound) & (F.col(\"MONTHLY_INCOME\") <= upper_bound)\n)\n\noriginal_count = income_stats['TOTAL_ROWS']  # Snowflake uses uppercase column names\nfinal_count = final_df.count()\n\nst.success(f\"‚úÖ Shape of the dataset after cleaning: ({final_count}, {len(final_df.columns)})\")\nst.info(f\"üìâ Removed {original_count - final_count} outlier records from monthly_income\")\n\n# Store cleaned dataset\ncleaned_df = final_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2257f785-e164-4c98-a2bc-f051c6ead4cc",
   "metadata": {
    "language": "python",
    "name": "dep_and_role_analysis"
   },
   "outputs": [],
   "source": "# DEPARTMENT AND JOB ROLE ANALYSIS using Snowpark DataFrame with Interactive Streamlit Visualizations\nst.header(\"üè¢ Department & Job Role Analysis\")\nst.markdown(\"---\")\n\n# Get unique departments and job roles for dropdown options\n# Use cleaned dataset if available, otherwise use raw dataset\nanalysis_df = cleaned_df if 'cleaned_df' in locals() else raw_data_df\ndepartments = [row['DEPARTMENT'] for row in analysis_df.select(\"DEPARTMENT\").distinct().collect()]\njob_roles = [row['JOB_ROLE'] for row in analysis_df.select(\"JOB_ROLE\").distinct().collect()]\n\n# Create side-by-side columns for the interactive charts\ncol1, col2 = st.columns(2)\n\nwith col1:\n    st.subheader(\"üìä Department Analysis\")\n    \n    # Department dropdown\n    selected_dept = st.selectbox(\"Select Department:\", departments, key=\"dept_selector\")\n    \n    # Filter data for selected department\n    dept_data = analysis_df.filter(F.col(\"DEPARTMENT\") == selected_dept)\n    dept_total = dept_data.count()\n    dept_attritioned = dept_data.filter(F.col(\"ATTRITION\") == \"Yes\").count()\n    dept_retained = dept_total - dept_attritioned\n    dept_attrition_rate = (dept_attritioned / dept_total) * 100 if dept_total > 0 else 0\n    \n    # Display statistics\n    st.metric(\n        label=\"Attrition Rate\", \n        value=f\"{dept_attrition_rate:.1f}%\",\n        delta=f\"{dept_attritioned} out of {dept_total} employees\"\n    )\n    \n    # Create pie chart for department\n    if dept_total > 0:\n        fig1, ax1 = plt.subplots(figsize=(8, 6))\n        labels = ['Retained', 'Left Company']\n        sizes = [dept_retained, dept_attritioned]\n        colors = ['lightblue', 'salmon']\n        explode = (0.05, 0.05)  # slightly separate the slices\n        \n        ax1.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, \n                explode=explode, shadow=True, startangle=90)\n        ax1.set_title(f'Attrition in {selected_dept}', fontsize=14, fontweight='bold')\n        \n        st.pyplot(fig1)\n        plt.close()\n    else:\n        st.warning(\"No data available for selected department\")\n\nwith col2:\n    st.subheader(\"üëî Job Role Analysis\")\n    \n    # Job role dropdown\n    selected_role = st.selectbox(\"Select Job Role:\", job_roles, key=\"role_selector\")\n    \n    # Filter data for selected job role\n    role_data = analysis_df.filter(F.col(\"JOB_ROLE\") == selected_role)\n    role_total = role_data.count()\n    role_attritioned = role_data.filter(F.col(\"ATTRITION\") == \"Yes\").count()\n    role_retained = role_total - role_attritioned\n    role_attrition_rate = (role_attritioned / role_total) * 100 if role_total > 0 else 0\n    \n    # Display statistics\n    st.metric(\n        label=\"Attrition Rate\", \n        value=f\"{role_attrition_rate:.1f}%\",\n        delta=f\"{role_attritioned} out of {role_total} employees\"\n    )\n    \n    # Create pie chart for job role\n    if role_total > 0:\n        fig2, ax2 = plt.subplots(figsize=(8, 6))\n        labels = ['Retained', 'Left Company']\n        sizes = [role_retained, role_attritioned]\n        colors = ['lightgreen', 'orange']\n        explode = (0.05, 0.05)  # slightly separate the slices\n        \n        ax2.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, \n                explode=explode, shadow=True, startangle=90)\n        ax2.set_title(f'Attrition for {selected_role}', fontsize=14, fontweight='bold')\n        \n        st.pyplot(fig2)\n        plt.close()\n    else:\n        st.warning(\"No data available for selected job role\")\n\n# Summary table showing all departments and roles\nst.subheader(\"üìà Summary Tables\")\n\n# Create tabs for detailed breakdown\ntab1, tab2 = st.tabs([\"Department Breakdown\", \"Job Role Breakdown\"])\n\nwith tab1:\n    # Department analysis table using Snowpark DataFrame\n    dept_analysis = analysis_df.group_by(\"DEPARTMENT\").agg([\n        F.count(\"*\").alias(\"total_employees\"),\n        F.sum(F.when(F.col(\"ATTRITION\") == \"Yes\", 1).otherwise(0)).alias(\"attritioned\"),\n        F.avg(F.when(F.col(\"ATTRITION\") == \"Yes\", 1).otherwise(0)).alias(\"attrition_rate_decimal\")\n    ]).with_column(\"attrition_rate_pct\", F.col(\"attrition_rate_decimal\") * 100).order_by(F.col(\"attrition_rate_pct\").desc())\n    \n    st.dataframe(dept_analysis, use_container_width=True)\n\nwith tab2:\n    # Job role analysis table using Snowpark DataFrame\n    role_analysis = analysis_df.group_by(\"JOB_ROLE\").agg([\n        F.count(\"*\").alias(\"total_employees\"),\n        F.sum(F.when(F.col(\"ATTRITION\") == \"Yes\", 1).otherwise(0)).alias(\"attritioned\"),\n        F.avg(F.when(F.col(\"ATTRITION\") == \"Yes\", 1).otherwise(0)).alias(\"attrition_rate_decimal\")\n    ]).with_column(\"attrition_rate_pct\", F.col(\"attrition_rate_decimal\") * 100).order_by(F.col(\"attrition_rate_pct\").desc())\n    \n    st.dataframe(role_analysis, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0fcf241-c62a-4936-9d4f-5829a6b0d01c",
   "metadata": {
    "language": "python",
    "name": "overtime_analy"
   },
   "outputs": [],
   "source": "# OVERTIME ANALYSIS using Snowpark DataFrame\nprint(\"‚è∞ OVERTIME ANALYSIS\")\nprint(\"=\" * 50)\n\n# Overtime impact on attrition using Snowpark DataFrame\novertime_analysis = raw_data_df.group_by(\"OVER_TIME\").agg([\n    F.count(\"*\").alias(\"total_employees\"),\n    F.sum(F.when(F.col(\"ATTRITION\") == \"Yes\", 1).otherwise(0)).alias(\"attritioned\"),\n    F.avg(F.when(F.col(\"ATTRITION\") == \"Yes\", 1).otherwise(0)).alias(\"attrition_rate_decimal\")\n]).with_column(\"attrition_rate_pct\", F.col(\"attrition_rate_decimal\") * 100).order_by(\"OVER_TIME\")\n\nprint(\"üìä Attrition by Overtime Status:\")\novertime_results = overtime_analysis.collect()\novertime_dict = {}\nfor row in overtime_results:\n    status = row['OVER_TIME']\n    total = row['TOTAL_EMPLOYEES']\n    attritioned = row['ATTRITIONED']\n    rate = row['ATTRITION_RATE_PCT']\n    print(f\"  {status}: {total} total, {attritioned} left ({rate:.1f}%)\")\n    overtime_dict[status] = rate\n\n# Calculate the difference if we have both Yes and No\nif 'Yes' in overtime_dict and 'No' in overtime_dict:\n    overtime_diff = overtime_dict['Yes'] - overtime_dict['No']\n    print(f\"\\nüìà Overtime Impact: +{overtime_diff:.1f} percentage points\")\n    print(f\"üéØ Expected from Medium article: ~20 percentage points difference\")\n    print(f\"   (30.5% for overtime vs 10.4% for non-overtime)\")\n\n# Visualization using collected data\nplt.figure(figsize=(10, 6))\novertime_status = list(overtime_dict.keys())\novertime_rates = list(overtime_dict.values())\n\nplt.bar(overtime_status, overtime_rates, color=['mediumblue', 'lightblue'])\nplt.title('Attrition Rate by Overtime Status', fontsize=14, fontweight='bold')\nplt.xlabel('Overtime Status')\nplt.ylabel('Attrition Rate (%)')\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a7b0ca90-adeb-41b8-a42f-3ae13915cf69",
   "metadata": {
    "language": "python",
    "name": "heatmap"
   },
   "outputs": [],
   "source": "# 1. CORRELATION HEATMAP ANALYSIS\nst.subheader(\"üî• Feature Correlation Heatmap\")\nst.markdown(\"*Analyzing relationships between numerical features to identify patterns*\")\n\n# Get numerical columns for correlation analysis\n# Exclude EMPLOYEE_NUMBER if it exists, and get sample for correlation calculation\nnumerical_columns = []\nfor field in cleaned_df.schema.fields:\n    # Include numerical columns but exclude EMPLOYEE_NUMBER and ID-like fields  \n    datatype_str = str(field.datatype)\n    if (any(num_type in datatype_str for num_type in ['LongType', 'IntegerType', 'FloatType', 'DoubleType', 'DecimalType']) and \n        field.name not in ['EMPLOYEE_NUMBER', 'EMPLOYEE_COUNT']):\n        numerical_columns.append(field.name)\n\nif numerical_columns:\n    # Get sample data for correlation calculation (using pandas for correlation matrix)\n    st.info(f\"üìà Analyzing correlations for {len(numerical_columns)} numerical features\")\n    \n    # Sample data for correlation (limit to reasonable size for performance)\n    correlation_sample = cleaned_df.select(*numerical_columns).limit(1000).to_pandas()\n    \n    # Calculate correlation matrix\n    correlation_matrix = correlation_sample.corr()\n    \n    # Create heatmap\n    fig, ax = plt.subplots(figsize=(14, 12))\n    \n    # Generate heatmap with better styling\n    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask upper triangle\n    sns.heatmap(correlation_matrix, \n                mask=mask,\n                annot=True, \n                cmap='RdYlBu_r', \n                center=0,\n                square=True,\n                fmt='.2f', \n                cbar_kws={\"shrink\": .8},\n                ax=ax)\n    \n    ax.set_title('Feature Correlation Heatmap\\n(Lower Triangle Only)', fontsize=16, fontweight='bold', pad=20)\n    plt.xticks(rotation=45, ha='right')\n    plt.yticks(rotation=0)\n    plt.tight_layout()\n    st.pyplot(fig)\n    plt.close()\n    \n    # Find highly correlated features (absolute correlation > 0.7)\n    st.subheader(\"üîç Highly Correlated Feature Pairs\")\n    high_corr_pairs = []\n    import builtins  # Import builtins to access Python's built-in abs function\n    for i in range(len(correlation_matrix.columns)):\n        for j in range(i+1, len(correlation_matrix.columns)):\n            corr_value = correlation_matrix.iloc[i, j]\n            if builtins.abs(corr_value) > 0.7:\n                high_corr_pairs.append({\n                    'Feature 1': correlation_matrix.columns[i],\n                    'Feature 2': correlation_matrix.columns[j],\n                    'Correlation': corr_value\n                })\n    \n    if high_corr_pairs:\n        corr_df = pd.DataFrame(high_corr_pairs)\n        corr_df = corr_df.reindex(corr_df['Correlation'].abs().sort_values(ascending=False).index)\n        st.dataframe(corr_df, use_container_width=True)\n    else:\n        st.info(\"No highly correlated feature pairs found (threshold: |correlation| > 0.7)\")\nelse:\n    st.warning(\"No numerical columns found for correlation analysis\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f92fdff4-ad75-42ce-b437-85dd0cbfe927",
   "metadata": {
    "language": "python",
    "name": "demographic_analysis"
   },
   "outputs": [],
   "source": "# 2. GENDER AND AGE DISTRIBUTIONS\nst.subheader(\"üë• Gender & Age Distribution Analysis\")\nst.markdown(\"*Understanding demographic patterns in our workforce*\")\n\n# Create side-by-side analysis\ncol1, col2 = st.columns(2)\n\nwith col1:\n    st.markdown(\"**Gender Distribution**\")\n    \n    # Gender distribution using Snowpark DataFrame\n    gender_dist = cleaned_df.group_by(\"GENDER\").agg([\n        F.count(\"*\").alias(\"count\"),\n        F.avg(F.when(F.col(\"ATTRITION\") == \"Yes\", 1).otherwise(0)).alias(\"attrition_rate\")\n    ]).with_column(\"attrition_rate_pct\", F.col(\"attrition_rate\") * 100)\n    \n    gender_results = gender_dist.collect()\n    \n    # Prepare data for visualization\n    genders = [row['GENDER'] for row in gender_results]\n    gender_counts = [row['COUNT'] for row in gender_results]\n    gender_attrition_rates = [row['ATTRITION_RATE_PCT'] for row in gender_results]\n    \n    # Create gender distribution pie chart\n    fig1, ax1 = plt.subplots(figsize=(8, 6))\n    colors = ['lightblue', 'lightpink']\n    ax1.pie(gender_counts, labels=genders, autopct='%1.1f%%', colors=colors, \n            startangle=90, explode=(0.05, 0.05))\n    ax1.set_title('Employee Distribution by Gender', fontsize=12, fontweight='bold')\n    st.pyplot(fig1)\n    plt.close()\n    \n    # Display gender attrition rates\n    st.markdown(\"**Attrition Rate by Gender:**\")\n    for i, gender in enumerate(genders):\n        st.write(f\"- {gender}: {gender_attrition_rates[i]:.1f}%\")\n\nwith col2:\n    st.markdown(\"**Age Distribution**\")\n    \n    # Get age statistics using Snowpark\n    age_stats = cleaned_df.select([\n        F.min(\"AGE\").alias(\"min_age\"),\n        F.max(\"AGE\").alias(\"max_age\"),\n        F.avg(\"AGE\").alias(\"avg_age\"),\n        F.expr(\"percentile_cont(0.25) within group (order by AGE)\").alias(\"Q1\"),\n        F.expr(\"percentile_cont(0.50) within group (order by AGE)\").alias(\"median\"),\n        F.expr(\"percentile_cont(0.75) within group (order by AGE)\").alias(\"Q3\")\n    ]).collect()[0]\n    \n    # Display age statistics\n    st.metric(\"Average Age\", f\"{age_stats['AVG_AGE']:.1f} years\")\n    st.metric(\"Age Range\", f\"{age_stats['MIN_AGE']} - {age_stats['MAX_AGE']} years\")\n    st.metric(\"Median Age\", f\"{age_stats['MEDIAN']:.0f} years\")\n    \n    # Get age distribution data for histogram\n    age_sample = cleaned_df.select(\"AGE\", \"ATTRITION\").limit(1000).to_pandas()\n    \n    # Create age distribution histogram\n    fig2, ax2 = plt.subplots(figsize=(8, 6))\n    ax2.hist(age_sample['AGE'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n    ax2.axvline(age_stats['AVG_AGE'], color='red', linestyle='--', linewidth=2, \n                label=f'Mean: {age_stats[\"AVG_AGE\"]:.1f}')\n    ax2.axvline(age_stats['MEDIAN'], color='green', linestyle='--', linewidth=2, \n                label=f'Median: {age_stats[\"MEDIAN\"]:.0f}')\n    ax2.set_xlabel('Age')\n    ax2.set_ylabel('Frequency')\n    ax2.set_title('Age Distribution of Employees')\n    ax2.legend()\n    ax2.grid(axis='y', alpha=0.3)\n    st.pyplot(fig2)\n    plt.close()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e44bbde-5901-4430-bd25-d14b9053e6d4",
   "metadata": {
    "language": "python",
    "name": "demographic_analysis2",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "# 3. ATTRITION VS DENSITY BY GENDER\nst.subheader(\"‚öñÔ∏è Attrition Density Analysis by Gender\")\nst.markdown(\"*Comparing attrition patterns between male and female employees*\")\n\n# Get gender-specific attrition data using Snowpark\ngender_attrition_data = cleaned_df.select(\"GENDER\", \"AGE\", \"ATTRITION\", \"MONTHLY_INCOME\").to_pandas()\n\n# Create density plots for age by gender and attrition\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Age density by gender and attrition\nfor i, gender in enumerate(['Male', 'Female']):\n    gender_data = gender_attrition_data[gender_attrition_data['GENDER'] == gender]\n    \n    # Age density plot\n    ax = axes[0, i]\n    stayed = gender_data[gender_data['ATTRITION'] == 'No']['AGE']\n    left = gender_data[gender_data['ATTRITION'] == 'Yes']['AGE']\n    \n    ax.hist(stayed, bins=20, alpha=0.7, label='Stayed', color='lightblue', density=True)\n    ax.hist(left, bins=20, alpha=0.7, label='Left', color='salmon', density=True)\n    ax.set_title(f'Age Distribution - {gender}')\n    ax.set_xlabel('Age')\n    ax.set_ylabel('Density')\n    ax.legend()\n    ax.grid(axis='y', alpha=0.3)\n\n# Income density by gender and attrition  \nfor i, gender in enumerate(['Male', 'Female']):\n    gender_data = gender_attrition_data[gender_attrition_data['GENDER'] == gender]\n    \n    # Income density plot\n    ax = axes[1, i]\n    stayed = gender_data[gender_data['ATTRITION'] == 'No']['MONTHLY_INCOME']\n    left = gender_data[gender_data['ATTRITION'] == 'Yes']['MONTHLY_INCOME']\n    \n    ax.hist(stayed, bins=20, alpha=0.7, label='Stayed', color='lightgreen', density=True)\n    ax.hist(left, bins=20, alpha=0.7, label='Left', color='orange', density=True)\n    ax.set_title(f'Income Distribution - {gender}')\n    ax.set_xlabel('Monthly Income ($)')\n    ax.set_ylabel('Density')\n    ax.legend()\n    ax.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nst.pyplot(fig)\nplt.close()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e56ceaae-8c98-4752-be8f-402a5ea7dca7",
   "metadata": {
    "language": "python",
    "name": "income_attrition",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "# MONTHLY INCOME CORRELATION WITH ATTRITION  \nst.subheader(\"üí∞ Monthly Income Correlation with Attrition\")  \nst.markdown(\"*Analyzing how monthly income levels correlate with employee attrition rates*\")  \n# Get income and attrition data using Snowpark  \nincome_attrition_data = cleaned_df.select(\"MONTHLY_INCOME\", \"ATTRITION\").to_pandas()  \n# Create income analysis visualizations  \nfig, axes = plt.subplots(2, 2, figsize=(15, 10))  \n# Income distribution by attrition status  \nax = axes[0, 0]  \nstayed = income_attrition_data[income_attrition_data['ATTRITION'] == 'No']['MONTHLY_INCOME']  \nleft = income_attrition_data[income_attrition_data['ATTRITION'] == 'Yes']['MONTHLY_INCOME']  \nax.hist(stayed, bins=30, alpha=0.7, label='Stayed', color='lightblue', density=True)  \nax.hist(left, bins=30, alpha=0.7, label='Left', color='salmon', density=True)  \nax.set_title('Monthly Income Distribution by Attrition')  \nax.set_xlabel('Monthly Income ($)')  \nax.set_ylabel('Density')  \nax.legend()  \nax.grid(axis='y', alpha=0.3)  \n# Box plot comparison  \nax = axes[0, 1]  \nincome_attrition_data.boxplot(column='MONTHLY_INCOME', by='ATTRITION', ax=ax)  \nax.set_title('Monthly Income Box Plot by Attrition Status')  \nax.set_xlabel('Attrition Status')  \nax.set_ylabel('Monthly Income ($)')  \n# Income bins analysis  \nincome_attrition_data['INCOME_BIN'] = pd.cut(income_attrition_data['MONTHLY_INCOME'],   \n                                           bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])  \n# Attrition rate by income bin  \nax = axes[1, 0]  \nattrition_by_income = income_attrition_data.groupby('INCOME_BIN')['ATTRITION'].apply(  \n    lambda x: (x == 'Yes').sum() / len(x) * 100  \n).reset_index()  \nattrition_by_income.columns = ['INCOME_BIN', 'ATTRITION_RATE']  \nbars = ax.bar(attrition_by_income['INCOME_BIN'], attrition_by_income['ATTRITION_RATE'],   \n              color='coral', alpha=0.7)  \nax.set_title('Attrition Rate by Income Level')  \nax.set_xlabel('Income Level')  \nax.set_ylabel('Attrition Rate (%)')  \nax.grid(axis='y', alpha=0.3)  \n# Add value labels on bars  \nfor bar in bars:  \n    height = bar.get_height()  \n    ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,  \n            f'{height:.1f}%', ha='center', va='bottom')  \n# Count by income bin and attrition  \nax = axes[1, 1]  \nincome_counts = income_attrition_data.groupby(['INCOME_BIN', 'ATTRITION']).size().unstack()  \nincome_counts.plot(kind='bar', ax=ax, color=['lightblue', 'salmon'], alpha=0.7)  \nax.set_title('Employee Count by Income Level and Attrition')  \nax.set_xlabel('Income Level')  \nax.set_ylabel('Employee Count')  \nax.legend(title='Attrition')  \nax.grid(axis='y', alpha=0.3)  \nplt.setp(ax.get_xticklabels(), rotation=45)  \nplt.tight_layout()  \nst.pyplot(fig)  \nplt.close()  \n# Statistical summary  \nst.subheader(\"üìà Income-Attrition Statistical Summary\")  \ncol1, col2 = st.columns(2)  \nwith col1:  \n    st.write(\"**Average Monthly Income by Attrition Status:**\")  \n    avg_income = income_attrition_data.groupby('ATTRITION')['MONTHLY_INCOME'].agg(['mean', 'median', 'std'])  \n    st.dataframe(avg_income.round(2))  \nwith col2:  \n    st.write(\"**Attrition Rate by Income Quartile:**\")  \n    income_attrition_data['INCOME_QUARTILE'] = pd.qcut(income_attrition_data['MONTHLY_INCOME'],   \n                                                      q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])  \n    quartile_attrition = income_attrition_data.groupby('INCOME_QUARTILE')['ATTRITION'].apply(  \n        lambda x: (x == 'Yes').sum() / len(x) * 100  \n    ).round(2)  \n    st.dataframe(quartile_attrition.to_frame('Attrition Rate (%)'))  ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "43cb561e-86d9-492b-aa1f-cd85911d57f7",
   "metadata": {
    "language": "python",
    "name": "position_attrition",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "# 5. ATTRITION RATE BY POSITION (JOB ROLE)\nst.subheader(\"üéØ Attrition Rate by Position\")\nst.markdown(\"*Identifying which job roles have the highest turnover risk*\")\n\n# Job role attrition analysis using Snowpark\njob_role_analysis = cleaned_df.group_by(\"JOB_ROLE\").agg([\n    F.count(\"*\").alias(\"total_employees\"),\n    F.sum(F.when(F.col(\"ATTRITION\") == \"Yes\", 1).otherwise(0)).alias(\"attritioned\"),\n    F.avg(F.when(F.col(\"ATTRITION\") == \"Yes\", 1).otherwise(0)).alias(\"attrition_rate_decimal\")\n]).with_column(\"attrition_rate_pct\", F.col(\"attrition_rate_decimal\") * 100)\\\n  .filter(F.col(\"total_employees\") >= 5)\\\n  .order_by(F.col(\"attrition_rate_pct\").desc())\n\njob_role_results = job_role_analysis.collect()\n\n# Display top positions with highest attrition\ncol1, col2 = st.columns([2, 1])\n\nwith col1:\n    # Create horizontal bar chart for better readability\n    positions = [row['JOB_ROLE'] for row in job_role_results[:10]]  # Top 10\n    attrition_rates = [row['ATTRITION_RATE_PCT'] for row in job_role_results[:10]]\n    \n    fig, ax = plt.subplots(figsize=(12, 8))\n    bars = ax.barh(positions, attrition_rates, color='salmon')\n    ax.set_xlabel('Attrition Rate (%)')\n    ax.set_title('Top 10 Positions by Attrition Rate', fontsize=14, fontweight='bold')\n    ax.grid(axis='x', alpha=0.3)\n    \n    # Add percentage labels on bars\n    for bar, rate in zip(bars, attrition_rates):\n        width = bar.get_width()\n        ax.text(width + 0.5, bar.get_y() + bar.get_height()/2, \n                f'{rate:.1f}%', ha='left', va='center', fontweight='bold')\n    \n    plt.tight_layout()\n    st.pyplot(fig)\n    plt.close()\n\nwith col2:\n    st.markdown(\"**üìä Position Risk Summary**\")\n    for i, row in enumerate(job_role_results[:5]):  # Top 5 highest risk\n        role = row['JOB_ROLE']\n        rate = row['ATTRITION_RATE_PCT']\n        total = row['TOTAL_EMPLOYEES']\n        attritioned = row['ATTRITIONED']\n        \n        st.write(f\"**{i+1}. {role}**\")\n        st.write(f\"   Rate: {rate:.1f}%\")\n        st.write(f\"   ({attritioned}/{total} employees)\")\n        st.write(\"\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d9e2566-5d71-465c-a975-af09771d5ef2",
   "metadata": {
    "language": "python",
    "name": "job_sat_attrition"
   },
   "outputs": [],
   "source": "# 6. JOB SATISFACTION ANALYSIS\nst.subheader(\"üòä Job Satisfaction Analysis\")\nst.markdown(\"*Understanding the relationship between job satisfaction and employee retention*\")\n\n# Job satisfaction analysis using Snowpark DataFrame\nsatisfaction_analysis = cleaned_df.group_by(\"JOB_SATISFACTION\").agg([\n    F.count(\"*\").alias(\"total_employees\"),\n    F.sum(F.when(F.col(\"ATTRITION\") == \"Yes\", 1).otherwise(0)).alias(\"attritioned\"),\n    F.avg(F.when(F.col(\"ATTRITION\") == \"Yes\", 1).otherwise(0)).alias(\"attrition_rate_decimal\")\n]).with_column(\"attrition_rate_pct\", F.col(\"attrition_rate_decimal\") * 100)\\\n  .order_by(\"JOB_SATISFACTION\")\n\nsatisfaction_results = satisfaction_analysis.collect()\n\n# Create side-by-side analysis\ncol1, col2 = st.columns(2)\n\nwith col1:\n    st.markdown(\"**üìä Satisfaction Levels Distribution**\")\n    \n    # Satisfaction level distribution\n    satisfaction_levels = [row['JOB_SATISFACTION'] for row in satisfaction_results]\n    satisfaction_counts = [row['TOTAL_EMPLOYEES'] for row in satisfaction_results]\n    \n    fig1, ax1 = plt.subplots(figsize=(8, 6))\n    bars = ax1.bar(satisfaction_levels, satisfaction_counts, color='lightblue', alpha=0.8)\n    ax1.set_xlabel('Job Satisfaction Level')\n    ax1.set_ylabel('Number of Employees')\n    ax1.set_title('Employee Distribution by Job Satisfaction Level')\n    ax1.grid(axis='y', alpha=0.3)\n    \n    # Add count labels on bars\n    for bar, count in zip(bars, satisfaction_counts):\n        height = bar.get_height()\n        ax1.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n                f'{count}', ha='center', va='bottom', fontweight='bold')\n    \n    st.pyplot(fig1)\n    plt.close()\n\nwith col2:\n    st.markdown(\"**‚ö†Ô∏è Attrition Rate by Satisfaction Level**\")\n    \n    # Attrition rate by satisfaction level\n    attrition_rates = [row['ATTRITION_RATE_PCT'] for row in satisfaction_results]\n    \n    fig2, ax2 = plt.subplots(figsize=(8, 6))\n    bars = ax2.bar(satisfaction_levels, attrition_rates, color='salmon', alpha=0.8)\n    ax2.set_xlabel('Job Satisfaction Level')\n    ax2.set_ylabel('Attrition Rate (%)')\n    ax2.set_title('Attrition Rate by Job Satisfaction Level')\n    ax2.grid(axis='y', alpha=0.3)\n    \n    # Add percentage labels on bars\n    for bar, rate in zip(bars, attrition_rates):\n        height = bar.get_height()\n        ax2.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n                f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')\n    \n    st.pyplot(fig2)\n    plt.close()\n\n# Detailed satisfaction analysis table\nst.subheader(\"üìã Detailed Job Satisfaction Analysis\")\n\n# Create a more readable table\nsatisfaction_display = []\nfor row in satisfaction_results:\n    satisfaction_display.append({\n        'Satisfaction Level': f\"Level {row['JOB_SATISFACTION']}\",\n        'Total Employees': row['TOTAL_EMPLOYEES'],\n        'Employees Who Left': row['ATTRITIONED'],\n        'Attrition Rate (%)': f\"{row['ATTRITION_RATE_PCT']:.1f}%\"\n    })\nsatisfaction_df = pd.DataFrame(satisfaction_display)\nst.dataframe(satisfaction_df, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e86a208f-a59b-4019-94fb-54648ee1cbcb",
   "metadata": {
    "language": "python",
    "name": "pairwise_corr"
   },
   "outputs": [],
   "source": "# 7. PAIRWISE PLOTS FOR KEY FEATURES  \nst.subheader(\"üîó Pairwise Relationships Analysis\")\n# Define specific columns for pairwise analysis (matching your sample code)\ncols = ['TOTAL_WORKING_YEARS', 'YEARS_AT_COMPANY', 'YEARS_IN_CURRENT_ROLE', \n        'YEARS_SINCE_LAST_PROMOTION', 'ATTRITION', 'JOB_LEVEL']\n# Check which features exist in our dataset\navailable_features = []\nfor feature in cols:\n    if feature in [field.name for field in cleaned_df.schema.fields]:\n        available_features.append(feature)\n\nif len(available_features) >= 3:\n    st.info(f\"üìä Creating pairwise plots for: {', '.join(available_features)}\")\n    \n    # Get sample data for pairwise plotting (pandas required for seaborn pairplot)\n    pairwise_sample = cleaned_df.select(*available_features).limit(500).to_pandas()\n    \n    # Create pairwise plot with seaborn - simple approach matching your sample\n    st.subheader(\"üìà Pairwise Feature Relationships\")\n    \n    # Use seaborn pairplot with hue for attrition (simple approach)\n    pair_plot = sns.pairplot(pairwise_sample, hue='ATTRITION')\n    \n    # Customize the plot\n    pair_plot.fig.suptitle('Pairwise Relationships - Tenure Features vs Attrition', \n                          fontsize=16, fontweight='bold', y=1.02)\n    \n    st.pyplot(pair_plot.fig)\n    plt.close()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1bb1ae1-7fcf-4f63-bb75-f6f33adec7ac",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "# # ========================================\n# # FEATURE ENGINEERING & MODEL PREPARATION\n# # ========================================\n# st.header(\"üõ†Ô∏è Feature Engineering & Model Preparation\")\n# st.markdown(\"---\")\n# st.markdown(\"*Preparing data for machine learning following Snowflake ML best practices*\")\n\n# # Display current dataset info\n# total_rows = cleaned_df.count()\n# total_cols = len(cleaned_df.columns)\n# st.info(f\"üìä **Starting Dataset**: {total_rows:,} rows √ó {total_cols} columns\")\n\n# # Check for EMPLOYEE_NUMBER column (to exclude from modeling)\n# schema_fields = [field.name for field in cleaned_df.schema.fields]\n# if 'EMPLOYEE_NUMBER' in schema_fields:\n#     st.warning(\"üìã **Note**: EMPLOYEE_NUMBER will be kept for reference but excluded from model training\")\n\n# print(\"üöÄ Starting Feature Engineering Pipeline...\")\n# print(\"=\" * 60)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ee9ea494-258c-40ff-bcd0-2ecc952655da",
   "metadata": {
    "language": "python",
    "name": "feature_engineering1",
    "collapsed": true,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Feature engineering pipeline\nprint(\"Starting feature engineering...\")\n\n# Define column types for encoding\nordinal_columns = [\n    'EDUCATION', 'ENVIRONMENT_SATISFACTION', 'JOB_LEVEL',\n    'JOB_SATISFACTION', 'RELATIONSHIP_SATISFACTION', 'WORK_LIFE_BALANCE'\n]\n\n# Categorize columns\ncategorical_columns = []\nordinal_columns_present = []\nnumerical_columns = []\ntarget_column = 'ATTRITION'\nexclude_columns = ['EMPLOYEE_NUMBER'] if 'EMPLOYEE_NUMBER' in [f.name for f in cleaned_df.schema.fields] else []\n\n# Analyze columns and categorize\nfor field in cleaned_df.schema.fields:\n    col_name = field.name\n    datatype_str = str(field.datatype)\n    \n    if col_name == target_column or col_name in exclude_columns:\n        continue\n    \n    if col_name in ordinal_columns:\n        ordinal_columns_present.append(col_name)\n    elif any(num_type in datatype_str for num_type in ['LongType', 'IntegerType', 'FloatType', 'DoubleType', 'DecimalType']):\n        unique_count = cleaned_df.select(col_name).distinct().count()\n        if unique_count <= 10 and col_name not in ordinal_columns:\n            categorical_columns.append(col_name)\n        else:\n            numerical_columns.append(col_name)\n    else:\n        categorical_columns.append(col_name)\n\nprint(f\"Ordinal columns: {len(ordinal_columns_present)}\")\nprint(f\"Categorical columns: {len(categorical_columns)}\")\nprint(f\"Numerical columns: {len(numerical_columns)}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b6f344a5-9dc7-4c77-8e05-27a021710788",
   "metadata": {
    "language": "python",
    "name": "feature_engineering2"
   },
   "outputs": [],
   "source": "# Apply feature encoding\nfeature_df = cleaned_df\n\n# Ordinal encoding\nif ordinal_columns_present:\n    print(\"Applying ordinal encoding...\")\n    ordinal_encoder = OrdinalEncoder(\n        input_cols=ordinal_columns_present,\n        output_cols=[f\"{col}_ORDINAL\" for col in ordinal_columns_present]\n    )\n    ordinal_encoder.fit(feature_df)\n    feature_df = ordinal_encoder.transform(feature_df)\n    feature_df = feature_df.drop(*ordinal_columns_present)\n    ordinal_encoded_columns = [f\"{col}_ORDINAL\" for col in ordinal_columns_present]\n    print(f\"Ordinal encoded: {len(ordinal_encoded_columns)} columns\")\nelse:\n    ordinal_encoded_columns = []\n\n# One-hot encoding\nif categorical_columns:\n    print(\"Applying one-hot encoding...\")\n    ohe = OneHotEncoder(\n        input_cols=categorical_columns,\n        output_cols=[f\"{col}_ONEHOT\" for col in categorical_columns]\n    )\n    ohe.fit(feature_df)\n    feature_df = ohe.transform(feature_df)\n    feature_df = feature_df.drop(*categorical_columns)\n    onehot_encoded_columns = [f\"{col}_ONEHOT\" for col in categorical_columns]\n    print(f\"One-hot encoded: {len(onehot_encoded_columns)} columns\")\nelse:\n    onehot_encoded_columns = []\n\n# Standard scaling for numerical features\nif numerical_columns:\n    print(\"Applying standard scaling...\")\n    scaler = StandardScaler(\n        input_cols=numerical_columns,\n        output_cols=[f\"{col}_SCALED\" for col in numerical_columns]\n    )\n    scaler.fit(feature_df)\n    feature_df = scaler.transform(feature_df)\n    feature_df = feature_df.drop(*numerical_columns)\n    scaled_columns = [f\"{col}_SCALED\" for col in numerical_columns]\n    print(f\"Scaled: {len(scaled_columns)} columns\")\nelse:\n    scaled_columns = []\n\nprint(\"Feature engineering complete!\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4c9a2424-8b6c-4dd1-a852-0556c7bd8467",
   "metadata": {
    "language": "python",
    "name": "train_test_split"
   },
   "outputs": [],
   "source": "# Convert ATTRITION to numeric (0/1) for ML\nfrom snowflake.snowpark.functions import col, when\nfeature_df = feature_df.with_column(\"ATTRITION\", \n    when(col(\"ATTRITION\") == \"Yes\", 1).otherwise(0).cast(LongType()))\n\n# Train/test split (80/20)\nprint(\"Creating train/test split...\")\ntrain_df, test_df = feature_df.random_split(weights=[0.8, 0.2], seed=42)\n\ntrain_count = train_df.count()\ntest_count = test_df.count()\nprint(f\"Training set: {train_count} samples\")\nprint(f\"Test set: {test_count} samples\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5ddccd04-b20e-4238-992a-f3f4167d05db",
   "metadata": {
    "language": "python",
    "name": "write_train_test"
   },
   "outputs": [],
   "source": "train_df.write.save_as_table('HR_ANALYTICS.ML_MODELING.HR_EMPLOYEE_ATTRITION_TRAIN_DF', mode = 'overwrite')\ntest_df.write.save_as_table('HR_ANALYTICS.ML_MODELING.HR_EMPLOYEE_ATTRITION_TEST_DF', mode = 'overwrite')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "50bc5eb7-3579-4e04-b67d-8833532a2a1c",
   "metadata": {
    "language": "python",
    "name": "read_train_test"
   },
   "outputs": [],
   "source": "train_df = session.read.table(\"HR_ANALYTICS.ML_MODELING.HR_EMPLOYEE_ATTRITION_TRAIN_DF\")\ntest_df = session.read.table(\"HR_ANALYTICS.ML_MODELING.HR_EMPLOYEE_ATTRITION_TEST_DF\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c03c9ddc-765c-4c19-955b-bc66e4736b49",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "test_df.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "25a3b603-1b2c-4832-8fba-3e72b89fcf1e",
   "metadata": {
    "language": "python",
    "name": "wh_up"
   },
   "outputs": [],
   "source": "wh = str(session.get_current_warehouse()).strip('\"')\nprint(f\"Current warehouse: {wh}\")\nprint(session.sql(f\"SHOW WAREHOUSES LIKE '{wh}';\").collect())\n\nsession.sql(f\"alter warehouse {session.get_current_warehouse()} set WAREHOUSE_SIZE = LARGE WAIT_FOR_COMPLETION = TRUE\").collect()\n\nprint(session.sql(f\"SHOW WAREHOUSES LIKE '{wh}';\").collect())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1f6aea2-871f-455b-b252-1f3cdc86e1b8",
   "metadata": {
    "language": "python",
    "name": "random_forest_train"
   },
   "outputs": [],
   "source": "# ========================================\n# XGBOOST MODEL WITH GRID SEARCH\n# ========================================\nst.header(\"üöÄ XGBoost Classifier with Grid Search\")\n# Import required libraries\nfrom snowflake.ml.modeling.xgboost import XGBClassifier\nfrom snowflake.ml.modeling.model_selection import GridSearchCV\nfrom snowflake.ml.modeling.metrics import accuracy_score, roc_auc_score\nimport pandas as pd\n\nprint(\"üöÄ Training XGBoost with Grid Search...\")\n\n# Define target column and feature columns\ntarget_column = ['ATTRITION']\noutput_column = ['PRED_ATTRITION']\nexclude_columns = ['EMPLOYEE_NUMBER'] if 'EMPLOYEE_NUMBER' in train_df.columns else []\n\n# Get all feature columns (exclude target and passthrough columns)\nall_columns = train_df.columns\nmodel_feature_columns = [col for col in all_columns if col not in target_column and col not in exclude_columns]\n\nprint(f\"üìä Using {len(model_feature_columns)} features for training\")\nprint(f\"üéØ Target column: {target_column}\")\n\n\n# Create GridSearchCV\nmodel_pipeline = GridSearchCV(\n    estimator=XGBClassifier(),\n    param_grid={\n        'n_estimators': [50, 100],\n        'learning_rate': [0.01, 0.1],\n        'max_depth': range(2,6,1)\n    },\n    n_jobs=-1,\n    input_cols=model_feature_columns,\n    passthrough_cols = exclude_columns,\n    label_cols=target_column,\n    output_cols=output_column,\n)\n\nprint(\"üîß Fitting XGBoost model with Grid Search...\")\n\n# Fit the model with grid search\nfitted_model = model_pipeline.fit(train_df)\n\nprint(\"‚úÖ XGBoost Grid Search training completed!\")\n\n\n# Make predictions\nprint(\"üîÆ Making predictions...\")\nxgb_gs_train = model_pipeline.predict(train_df)\nxgb_gs_predictions = model_pipeline.predict(test_df)\n\nst.success(\"‚úÖ **XGBoost with Grid Search trained successfully!**\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "05fc3f8a-6f90-48f9-aecd-60d0c830f457",
   "metadata": {
    "language": "python",
    "name": "ACC_AUC"
   },
   "outputs": [],
   "source": "# Calculate accuracy scores\ntrain_accuracy = accuracy_score(df=xgb_gs_train, y_true_col_names=target_column, y_pred_col_names=output_column)\ntest_accuracy = accuracy_score(df=xgb_gs_predictions, y_true_col_names=target_column, y_pred_col_names=output_column)\nprint(f'Test Accuracy: {test_accuracy}')\n\n# ROC AUC scores\ntrain_auc = roc_auc_score(df=xgb_gs_train, y_true_col_names=target_column, y_score_col_names=output_column)\ntest_auc = roc_auc_score(df=xgb_gs_predictions, y_true_col_names=target_column, y_score_col_names=output_column)\nprint(f'Test AUC: {test_auc}')\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea2bf798-2e42-4c0f-9cc6-1e190976de6e",
   "metadata": {
    "language": "python",
    "name": "model_results"
   },
   "outputs": [],
   "source": "# Grid Search Results Analysis and Feature Importance\nst.header(\"üìä Grid Search Analysis & Feature Importance\")\nst.markdown(\"---\")\n\nprint(\"üìà Analyzing Grid Search Results...\")\n\n# Use the fitted model\nfitted_model = model_pipeline\n\n# Get grid search results\ngs_results = fitted_model.to_sklearn().cv_results_\nn_estimators_val = []\nlearning_rate_val = []\nfor param_dict in gs_results[\"params\"]:\n    n_estimators_val.append(param_dict[\"n_estimators\"])\n    learning_rate_val.append(param_dict[\"learning_rate\"])\nmape_val = gs_results[\"mean_test_score\"]\n\ngs_results_df = pd.DataFrame(data={\n    \"n_estimators\": n_estimators_val,\n    \"learning_rate\": learning_rate_val,\n    \"mape\": mape_val\n})\n\nst.subheader(\"üîç Grid Search Parameter Performance\")\n\n# Display grid search results summary\ncol1, col2 = st.columns(2)\n\nwith col1:\n    st.write(\"**üìã Grid Search Results Summary:**\")\n    st.dataframe(gs_results_df.sort_values('mape', ascending=False).head(10))\n\nwith col2:\n    # Plot grid search results\n    sns.set_context(\"notebook\", font_scale=0.5)\n    fig = sns.relplot(data=gs_results_df, x=\"learning_rate\", y=\"mape\", hue=\"n_estimators\", kind=\"line\", height=3)\n    fig.set_xlabels('Learning Rate')\n    fig.set_ylabels('Mean Test Score (AUC)')\n    plt.title('Grid Search Results: Learning Rate vs Performance')\n    st.pyplot(fig)\n    plt.close()\n\n# Display best parameters and results\nst.subheader(\"üèÜ Best Model Results\")\n\nprint(\"Results from Grid Search\")\nprint(\"\\\\n The best estimator across ALL searched params:\\\\n\", fitted_model.to_sklearn().best_estimator_)\nprint(\"\\\\n The best score across ALL searched params:\\\\n\", fitted_model.to_sklearn().best_score_)\nprint(\"\\\\n The best parameters across ALL searched params:\\\\n\", fitted_model.to_sklearn().best_params_)\n\n# Display in Streamlit\ncol1, col2, col3 = st.columns(3)\n\nwith col1:\n    st.metric(\"Best Score (AUC)\", f\"{fitted_model.to_sklearn().best_score_:.4f}\")\n\nwith col2:\n    best_params = fitted_model.to_sklearn().best_params_\n    st.write(\"**Best Parameters:**\")\n    for param, value in best_params.items():\n        st.write(f\"- {param}: {value}\")\n\nwith col3:\n    st.write(\"**Model Performance:**\")\n    st.write(f\"- Training AUC: {train_auc:.4f}\")\n    st.write(f\"- Test AUC: {test_auc:.4f}\")\n    st.write(f\"- Training Accuracy: {train_accuracy:.4f}\")\n    st.write(f\"- Test Accuracy: {test_accuracy:.4f}\")\n\n# Feature Importance Analysis\nst.subheader(\"üéØ Feature Importance Analysis\")\n\n# Get feature importance from the BEST estimator (this was the issue!)\nbest_estimator = fitted_model.to_sklearn().best_estimator_\nfeature_names = fitted_model.to_sklearn().feature_names_in_\nfeature_importances = best_estimator.feature_importances_\n\n# Create feature importance DataFrame\nfeat_importance = pd.DataFrame({\n    'Feature': feature_names,\n    'FeatImportance': feature_importances\n}).sort_values('FeatImportance', ascending=True)\n\n# Plot feature importance\nfig, ax = plt.subplots(figsize=(10, 12))\nfeat_importance.plot.barh(x='Feature', y='FeatImportance', ax=ax, color='skyblue')\nax.set_title('Feature Importance - XGBoost Model', fontsize=14, fontweight='bold')\nax.set_xlabel('Feature Importance')\nax.grid(axis='x', alpha=0.3)\n\nst.pyplot(fig)\nplt.close()\n\n# Display top features\nst.subheader(\"üîù Top 10 Most Important Features\")\ntop_features = feat_importance.tail(10).sort_values('FeatImportance', ascending=False)\nst.dataframe(top_features, use_container_width=True)\n\nprint(\"‚úÖ Grid Search Analysis and Feature Importance completed!\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f1579edb-867b-4470-80e8-25cce215a088",
   "metadata": {
    "language": "python",
    "name": "wh_down"
   },
   "outputs": [],
   "source": "wh = str(session.get_current_warehouse()).strip('\"')\nprint(f\"Current warehouse: {wh}\")\nprint(session.sql(f\"SHOW WAREHOUSES LIKE '{wh}';\").collect())\n\nsession.sql(f\"alter warehouse {session.get_current_warehouse()} set WAREHOUSE_SIZE = XSMALL WAIT_FOR_COMPLETION = TRUE\").collect()\n\nprint(session.sql(f\"SHOW WAREHOUSES LIKE '{wh}';\").collect())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae5cc0f1-a395-41b5-bdb0-e01d6646b2ae",
   "metadata": {
    "language": "python",
    "name": "helper_fn"
   },
   "outputs": [],
   "source": "# FUNCTION used to iterate the model version so we can automatically \n# create the next version number\nimport ast\nimport builtins  # Import the builtins module\n#from snowflake.snowpark import functions as F \n\ndef get_next_version(reg, model_name) -> str:\n    \"\"\"\n    Returns the next version of a model based on the existing versions in the registry.\n\n    Args:\n        reg: The registry object that provides access to the models.\n        model_name: The name of the model.\n\n    Returns:\n        str: The next version of the model in the format \"V_\".\n\n    Raises:\n        ValueError: If the version list for the model is empty or if the version format is invalid.\n    \"\"\"\n    models = reg.show_models()\n    if models.empty:\n        return \"V_1\"\n    elif model_name not in models[\"name\"].to_list():\n        return \"V_1\"\n    max_version_number = builtins.max(  \n        [\n            int(version.split(\"_\")[-1])\n            for version in ast.literal_eval(\n                models.loc[models[\"name\"] == model_name, \"versions\"].values[0]\n            )\n        ]\n    )\n    return f\"V_{max_version_number + 1}\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b5cca85e-afcc-4837-8017-5d92d9164d55",
   "metadata": {
    "language": "python",
    "name": "reg_import"
   },
   "outputs": [],
   "source": "# Let's now register the CV Classfier model into the model_registry\nReg = Registry(\n    session=session,\n    database_name=session.get_current_database(),\n    schema_name='ML_MODELING',\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7a60e749-ebe3-4ef9-be03-b6369335f729",
   "metadata": {
    "language": "python",
    "name": "register_model",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "model_name = 'EMPLOYEE_ATTRITION_XGBOOST'\nmodel_version = get_next_version(Reg, model_name)\n\n# Get model parameters for comment\nmodel_params = model_pipeline.to_sklearn().get_params()\nparam_str = f\"n_estimators={model_params.get('n_estimators')}, learning_rate={model_params.get('learning_rate')}, max_depth={model_params.get('max_depth')}\"\n\nmv = Reg.log_model(fitted_model,\n    model_name=model_name,\n    version_name=model_version,\n    conda_dependencies=[\"snowflake-ml-python\"],\n    comment=f\"XGBoost model - Params: {param_str}\",\n    metrics={\"Test Acc\": test_accuracy, \"Test AUC\": test_auc, \"Train AUC\": train_auc, \"Train Acc\": train_accuracy}, # We can save our model metrics here\n    options= {\"relax_version\": False, \"enable_explainability\": True, 'case_sensitive': True},\n    \n)\nm = Reg.get_model(model_name)\nm.default = model_version",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5aef0d5d-9bf0-4425-9698-6c8a9914b6d5",
   "metadata": {
    "language": "python",
    "name": "check_model_versions"
   },
   "outputs": [],
   "source": "Reg.get_model(model_name).show_versions()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "80c74b33-dc32-417d-b366-ba6dbbf8a6c3",
   "metadata": {
    "language": "python",
    "name": "select_latest_model"
   },
   "outputs": [],
   "source": "prod_model = Reg.get_model(\"EMPLOYEE_ATTRITION_XGBOOST\").last() #or we can use .version()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff772ca4-96d6-46b4-b16e-1cab7845b2cf",
   "metadata": {
    "language": "python",
    "name": "inference"
   },
   "outputs": [],
   "source": "prod_model.run(test_df, function_name = 'PREDICT_PROBA')",
   "execution_count": null
  }
 ]
}